{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "category_dict = {\"안전/환경\": 1,\"미래\": 2,\"일자리\": 3,\"보건복지\": 4,\"정치개혁\": 5,\"경제민주화\": 6,\"인권/성평등\": 7,\"외교/통일/국방\": 8,\"육아/교육\": 9,\"문화/예술/체육/언론\": 10,\"반려동물\": 11,\"교통/건축/국토\": 12,\"행정\": 13,\"농산어촌\": 14,\"저출산/고령화대책\": 15,\"성장동력\": 16,\"기타\": 17}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 토큰화 된 corpus 데이터를 불러온다.\n",
    "with open('corpus2.json','r') as f:\n",
    "    json_corpus = json.load(f)\n",
    "    \n",
    "\n",
    "add_list = list()\n",
    "y_train = list()\n",
    "# target = '미래'\n",
    "for categ,value in json_corpus.items():\n",
    "#     if categ == '기타':\n",
    "#         break\n",
    "        \n",
    "    add_list.extend(value)\n",
    "    y_train.extend([category_dict[categ]]*len(value))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(add_list)    \n",
    "\n",
    "\n",
    "\n",
    "predict_unit = [json_corpus['기타'][1000]]\n",
    "test_unit = vectorizer.transform(predict_unit)\n",
    "    \n",
    "X,Y = shuffle(x_train,y_train)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split_value = round(len(X)*0.8)\n",
    "# x_train,y_train = X[:split_value],Y[:split_value]\n",
    "# x_test,y_test = X[split_value:],Y[split_value:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minwookje/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     24074\n",
      "           2       0.00      0.00      0.00     17133\n",
      "           3       0.00      0.00      0.00     19051\n",
      "           4       0.00      0.00      0.00     20654\n",
      "           5       0.15      0.94      0.25     42244\n",
      "           6       0.00      0.00      0.00     15708\n",
      "           7       0.00      0.00      0.00     26788\n",
      "           8       0.47      0.17      0.25     21697\n",
      "           9       0.25      0.29      0.27     21596\n",
      "          10       0.67      0.17      0.27     17677\n",
      "          11       0.00      0.00      0.00      9685\n",
      "          12       0.00      0.00      0.00     18418\n",
      "          13       0.00      0.00      0.00     18227\n",
      "          14       0.00      0.00      0.00      8388\n",
      "          15       0.00      0.00      0.00      9362\n",
      "          16       0.00      0.00      0.00     11404\n",
      "          17       0.00      0.00      0.00      7484\n",
      "\n",
      "   micro avg       0.17      0.17      0.17    309590\n",
      "   macro avg       0.09      0.09      0.06    309590\n",
      "weighted avg       0.11      0.17      0.09    309590\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00      8054\n",
      "           2       0.00      0.00      0.00      5626\n",
      "           3       0.00      0.00      0.00      6337\n",
      "           4       0.00      0.00      0.00      6839\n",
      "           5       0.15      0.93      0.25     14115\n",
      "           6       0.00      0.00      0.00      5136\n",
      "           7       0.00      0.00      0.00      9075\n",
      "           8       0.49      0.18      0.27      7272\n",
      "           9       0.24      0.28      0.26      7059\n",
      "          10       0.65      0.17      0.27      5970\n",
      "          11       0.00      0.00      0.00      3234\n",
      "          12       0.00      0.00      0.00      6022\n",
      "          13       0.00      0.00      0.00      6205\n",
      "          14       0.00      0.00      0.00      2873\n",
      "          15       0.00      0.00      0.00      3108\n",
      "          16       0.00      0.00      0.00      3756\n",
      "          17       0.00      0.00      0.00      2516\n",
      "\n",
      "   micro avg       0.17      0.17      0.17    103197\n",
      "   macro avg       0.09      0.09      0.06    103197\n",
      "weighted avg       0.11      0.17      0.09    103197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy', max_depth=3, min_samples_leaf=5).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_train, model.predict(x_train)))\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BreadCrumb_Accuracy: 0.140692074382\n",
      "Mean accuracy score: 0.141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "n_estimators = 100\n",
    "RF = RandomForestClassifier(max_depth=4, n_estimators=n_estimators)\n",
    "RF.fit(x_train,y_train)\n",
    "\n",
    "Output_predict = RF.predict(x_test)\n",
    "print (\"BreadCrumb_Accuracy: \" + str(np.mean(Output_predict == y_test)))\n",
    "accuracy = accuracy_score(y_test, Output_predict)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_multilabel = MLPClassifier(hidden_layer_sizes=(300,100), max_iter=200, \n",
    "                               random_state=42).fit(x_train, y_train)\n",
    "mlp_multilabel.score(x_test, y_test)\n",
    "Output_predict = mlp_multilabel.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, Output_predict)\n",
    "print(f'Mean accuracy score: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y,test,Output_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
