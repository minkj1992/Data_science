{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "category_dict = {\"안전/환경\": 1,\"미래\": 2,\"일자리\": 3,\"보건복지\": 4,\"정치개혁\": 5,\"경제민주화\": 6,\"인권/성평등\": 7,\"외교/통일/국방\": 8,\"육아/교육\": 9,\"문화/예술/체육/언론\": 10,\"반려동물\": 11,\"교통/건축/국토\": 12,\"행정\": 13,\"농산어촌\": 14,\"저출산/고령화대책\": 15,\"성장동력\": 16,\"기타\": 17}\n",
    "# tf_idf load\n",
    "#vectorizing 한 pickle 파일을 불러온다.\n",
    "# 육아/교육\": 9,\"문화/예술/체육/언론\": 10,\"반려동물\": 11,\"교통/건축/국토\": 12,\"행정\": 13,\"농산어촌\": 14,\"저출산/고령화대책\": 15,\"성장동력\": 16,\"기타\": 17}\n",
    "##here\n",
    "category = \"성장동력\"\n",
    "data_name = category_dict[category]\n",
    "path  = './'+str(data_name)+'.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 된 corpus 데이터를 불러온다.\n",
    "with open('corpus2.json','r') as f:\n",
    "    json_corpus = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_list = list()\n",
    "for categ,value in json_corpus.items():\n",
    "    add_list.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json 변환(단어: tfidf )\n",
    "def display_scores(vectorizer, tfidf_result, d_num):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)/d_num).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101798\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(add_list)\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = display_scores(vectorizer, x_train,len(add_list))\n",
    "# name = './'+str(data_name)+'_voca.json'\n",
    "name = './total_voca.json'\n",
    "with open(name,'w') as f:\n",
    "    json.dump(dict(tmp),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this car got the excellence award\n",
      "\t [('got', 0.4689132131547637), ('excellence', 0.4689132131547637), ('award', 0.4689132131547637), ('the', 0.37831622785558378), ('this', 0.3140366438234139), ('car', 0.3140366438234139)]\n",
      "good car gives good mileage\n",
      "\t [('good', 0.71788218051154329), ('gives', 0.44489822950274938), ('mileage', 0.44489822950274938), ('car', 0.2979535293877717)]\n",
      "this car is very expensive\n",
      "\t [('expensive', 0.57769147937522325), ('very', 0.4660778481185906), ('this', 0.38688671647327205), ('car', 0.38688671647327205), ('is', 0.38688671647327205)]\n",
      "the company is growing with very high production\n",
      "\t [('growing', 0.39524574252810757), ('with', 0.39524574252810757), ('high', 0.39524574252810757), ('production', 0.39524574252810757), ('the', 0.31888177640211135), ('company', 0.31888177640211135), ('very', 0.31888177640211135), ('is', 0.26470068018333703)]\n",
      "this company is financially good\n",
      "\t [('financially', 0.55911663430267555), ('company', 0.45109178007079426), ('good', 0.45109178007079426), ('this', 0.37444692624667947), ('is', 0.37444692624667947)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import operator\n",
    " \n",
    "corpus=[\"this car got the excellence award\",\\\n",
    "         \"good car gives good mileage\",\\\n",
    "         \"this car is very expensive\",\\\n",
    "         \"the company is growing with very high production\",\\\n",
    "         \"this company is financially good\"]\n",
    " \n",
    "vocabulary = set()\n",
    "for doc in corpus:\n",
    "    vocabulary.update(doc.split())\n",
    " \n",
    "vocabulary = list(vocabulary)\n",
    "word_index = {w: idx for idx, w in enumerate(vocabulary)}\n",
    " \n",
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)\n",
    " \n",
    "# Fit the TfIdf model\n",
    "tfidf.fit(corpus)\n",
    "tfidf.transform(corpus)\n",
    " \n",
    "for doc in corpus:\n",
    "    score={}\n",
    "    print(doc)\n",
    "    # Transform a document into TfIdf coordinates\n",
    "    X = tfidf.transform([doc])\n",
    "    for word in doc.split():\n",
    "        score[word] = X[0, tfidf.vocabulary_[word]]\n",
    "    sortedscore = sorted(score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    print(\"\\t\", sortedscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
